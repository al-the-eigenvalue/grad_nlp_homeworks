{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1dba7c0d",
      "metadata": {
        "id": "1dba7c0d"
      },
      "source": [
        "# Домашнее задание № 10. Машинный перевод"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Yj7aripVIsbG",
      "metadata": {
        "id": "Yj7aripVIsbG"
      },
      "source": [
        "## Задание 1 (6 баллов + 2 доп балла).\n",
        "Нужно обучить трансформер на том же корпусе но в другую сторону - с русского на английский.\n",
        "Можно использовать как основу первый или второй способ реализации (с MultiheadAttention или с nn.Transformer). Подберите несколько тестовых примеров для проверки обучения на каждой эпохе.\n",
        "\n",
        "Параметры ниже точно работают в колабе и модель обучается достаточно быстро. Попробуйте их немного увеличить (batch size возможно придется наоборот уменьшить). Обучайте модель хотя бы 5 эпох, а желательно больше, чтобы тестовые примеры начали переводиться более менее адекватно.\n",
        "\n",
        "После обучения возьмите хотя бы 100 примером из тестовой части параллельного корпуса и переведите их. Оцените качество переводов с помощью метрики BLEU (пример использования ниже)\n",
        "Найдите лучшие (как минимум 5) переводы согласно этой метрике и проверьте действительно ли они хорошие. Если все переводы нулевые, то пообучайте модель подольше.\n",
        "\n",
        "Чтобы получить 2 доп балла вам нужно будет придумать как оптимизировать функцию translate. Сейчас она работает только с одним текстом - это не эффективно. Можно генерировать переводы сразу для нескольких текстов (батча). Главная сложность с таким подходом состоит в том, что генерируемые тексты будут заканчиваться в разное время и нужно сделать столько итераций, сколько нужно для завершения всех текстов (т.е. условие на то, что последний токен не равен [EOS] в текущем коде не сработает).\n",
        "ВАЖНО - недостаточно просто изменить входной аргумент с text на texts и добавить еще один цикл по texts! Сама модель должна вызываться на нескольких текстах! Функция с batch prediction должна работать быстрее, поэтому переведите всю тестовую выборку и оцените качество BLEU на всех данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "05d202c4",
      "metadata": {
        "id": "05d202c4"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install torchtune torchao"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import nltk\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from timeit import default_timer as timer\n",
        "from tokenizers import decoders, Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from torchtune.modules import RotaryPositionalEmbeddings\n",
        "from tqdm.autonotebook import tqdm"
      ],
      "metadata": {
        "id": "gkG-7X3M6T-J"
      },
      "id": "gkG-7X3M6T-J",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt_tab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esc_V35S-KJl",
        "outputId": "77b9fa2e-f0e5-47a7-e9dd-36fce15b0167"
      },
      "id": "Esc_V35S-KJl",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Корпус"
      ],
      "metadata": {
        "id": "OUvPZHV_51rL"
      },
      "id": "OUvPZHV_51rL"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
        "\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJBHmZdX51Q3",
        "outputId": "24f3459b-6e8f-4d4d-9240-1c51c55a7f94"
      },
      "id": "fJBHmZdX51Q3",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-18 12:37:03--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121340806 (116M)\n",
            "Saving to: ‘opus.en-ru-train.ru’\n",
            "\n",
            "opus.en-ru-train.ru 100%[===================>] 115.72M  19.4MB/s    in 7.6s    \n",
            "\n",
            "2025-03-18 12:37:12 (15.3 MB/s) - ‘opus.en-ru-train.ru’ saved [121340806/121340806]\n",
            "\n",
            "--2025-03-18 12:37:12--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67760131 (65M)\n",
            "Saving to: ‘opus.en-ru-train.en’\n",
            "\n",
            "opus.en-ru-train.en 100%[===================>]  64.62M  16.6MB/s    in 4.8s    \n",
            "\n",
            "2025-03-18 12:37:17 (13.5 MB/s) - ‘opus.en-ru-train.en’ saved [67760131/67760131]\n",
            "\n",
            "--2025-03-18 12:37:17--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 305669 (299K)\n",
            "Saving to: ‘opus.en-ru-test.ru’\n",
            "\n",
            "opus.en-ru-test.ru  100%[===================>] 298.50K   408KB/s    in 0.7s    \n",
            "\n",
            "2025-03-18 12:37:19 (408 KB/s) - ‘opus.en-ru-test.ru’ saved [305669/305669]\n",
            "\n",
            "--2025-03-18 12:37:19--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 173307 (169K)\n",
            "Saving to: ‘opus.en-ru-test.en’\n",
            "\n",
            "opus.en-ru-test.en  100%[===================>] 169.25K   236KB/s    in 0.7s    \n",
            "\n",
            "2025-03-18 12:37:20 (236 KB/s) - ‘opus.en-ru-test.en’ saved [173307/173307]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(\"opus.en-ru-train.ru\").read().replace(\"\\xa0\", \" \")\n",
        "f = open(\"opus.en-ru-train.ru\", \"w\")\n",
        "f.write(text)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "XkXpJGIS57Uh"
      },
      "id": "XkXpJGIS57Uh",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_sents = open(\"opus.en-ru-train.en\").read().splitlines()\n",
        "ru_sents = open(\"opus.en-ru-train.ru\").read().splitlines()"
      ],
      "metadata": {
        "id": "mK5w1W-Y6I3_"
      },
      "id": "mK5w1W-Y6I3_",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Токенизация"
      ],
      "metadata": {
        "id": "W7Fw2fjG6-mg"
      },
      "id": "W7Fw2fjG6-mg"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en = Tokenizer(BPE())\n",
        "tokenizer_en.pre_tokenizer = Whitespace()\n",
        "trainer_en = BpeTrainer(special_tokens=[\"[PAD]\", \"[BOS]\", \"[EOS]\"], end_of_word_suffix=\"</w>\")\n",
        "tokenizer_en.train(files=[\"opus.en-ru-train.en\"], trainer=trainer_en)\n",
        "\n",
        "tokenizer_ru = Tokenizer(BPE())\n",
        "tokenizer_ru.pre_tokenizer = Whitespace()\n",
        "trainer_ru = BpeTrainer(special_tokens=[\"[PAD]\"], end_of_word_suffix=\"</w>\")\n",
        "tokenizer_ru.train(files=[\"opus.en-ru-train.ru\"], trainer=trainer_ru)"
      ],
      "metadata": {
        "id": "H7sFsXdi6QcZ"
      },
      "id": "H7sFsXdi6QcZ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en.decoder = decoders.BPEDecoder()\n",
        "tokenizer_ru.decoder = decoders.BPEDecoder()"
      ],
      "metadata": {
        "id": "FEmxadeu69a7"
      },
      "id": "FEmxadeu69a7",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en.save(\"tokenizer_en\")\n",
        "tokenizer_ru.save(\"tokenizer_ru\")"
      ],
      "metadata": {
        "id": "_3hF2PaY7BzV"
      },
      "id": "_3hF2PaY7BzV",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en = Tokenizer.from_file(\"tokenizer_en\")\n",
        "tokenizer_ru = Tokenizer.from_file(\"tokenizer_ru\")"
      ],
      "metadata": {
        "id": "z6WTeO6c7E_s"
      },
      "id": "z6WTeO6c7E_s",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text, tokenizer, max_len, encoder=False):\n",
        "    if encoder:\n",
        "        return tokenizer.encode(text).ids[:max_len]\n",
        "    else:\n",
        "        return (\n",
        "            [tokenizer.token_to_id(\"[BOS]\")]\n",
        "            + tokenizer.encode(text).ids[:max_len]\n",
        "            + [tokenizer.token_to_id(\"[EOS]\")]\n",
        "        )"
      ],
      "metadata": {
        "id": "8fA-oKM57J6J"
      },
      "id": "8fA-oKM57J6J",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Датасет"
      ],
      "metadata": {
        "id": "jpItSTFj8Lff"
      },
      "id": "jpItSTFj8Lff"
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_IDX = tokenizer_ru.token_to_id(\"[PAD]\")\n",
        "BOS_IDX = tokenizer_en.token_to_id(\"[BOS]\")\n",
        "EOS_IDX = tokenizer_en.token_to_id(\"[EOS]\")\n",
        "max_len_en, max_len_ru = 47, 48"
      ],
      "metadata": {
        "id": "qn1jyjWpQicc"
      },
      "id": "qn1jyjWpQicc",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_ru = [\n",
        "    encode(t, tokenizer_ru, max_len_ru, encoder=True)\n",
        "    for t in ru_sents\n",
        "]\n",
        "\n",
        "X_en = [\n",
        "    encode(t, tokenizer_en, max_len_en)\n",
        "    for t in en_sents\n",
        "]"
      ],
      "metadata": {
        "id": "VXo3FQB4QhkG"
      },
      "id": "VXo3FQB4QhkG",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_en_train, X_en_valid, X_ru_train, X_ru_valid = train_test_split(\n",
        "    X_en, X_ru, test_size=0.05\n",
        ")"
      ],
      "metadata": {
        "id": "p116-2z4PdpU"
      },
      "id": "p116-2z4PdpU",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, texts_ru, texts_en):\n",
        "        self.texts_ru = [torch.LongTensor(sent) for sent in texts_ru]\n",
        "        self.texts_ru = torch.nn.utils.rnn.pad_sequence(self.texts_ru, batch_first=True, padding_value=PAD_IDX)\n",
        "\n",
        "        self.texts_en = [torch.LongTensor(sent) for sent in texts_en]\n",
        "        self.texts_en = torch.nn.utils.rnn.pad_sequence(self.texts_en, batch_first=True, padding_value=PAD_IDX)\n",
        "\n",
        "        self.length = len(texts_en)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        ids_ru = self.texts_ru[index]\n",
        "        ids_en = self.texts_en[index]\n",
        "\n",
        "        return ids_ru, ids_en"
      ],
      "metadata": {
        "id": "se7Q10ew8NVH"
      },
      "id": "se7Q10ew8NVH",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 400\n",
        "\n",
        "training_set = Dataset(X_ru_train, X_en_train)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "valid_set = Dataset(X_ru_valid, X_en_valid)\n",
        "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "yBKXiQB1-u6e"
      },
      "id": "yBKXiQB1-u6e",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Трансформер"
      ],
      "metadata": {
        "id": "lX8UTAYc9Su-"
      },
      "id": "lX8UTAYc9Su-"
    },
    {
      "cell_type": "code",
      "source": [
        "# для encoder и decoder создается свой класс\n",
        "# это сделано для того чтобы можно было легко задать количество слоев как гиперпараметр\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(embed_dim, ff_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_dim, embed_dim),\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
        "        # здесь нормализация применяется после attention (как в оригинальной статье)\n",
        "        # сейчас чаще используют пре-нормализацию\n",
        "        src2, _ = self.self_attn(src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask) # mha\n",
        "        src = self.norm1(src + self.dropout(src2)) # norm + residual connection\n",
        "        src2 = self.ff(src) # ffd\n",
        "        src = self.norm2(src + self.dropout(src2)) # norm + residual connection\n",
        "\n",
        "        return src\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.cross_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.norm3 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(embed_dim, ff_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_dim, embed_dim),\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
        "        tgt2, _ = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask, key_padding_mask=tgt_key_padding_mask) # self mha\n",
        "        tgt = self.norm1(tgt + self.dropout(tgt2)) # norm + residual connection\n",
        "\n",
        "        tgt2, _ = self.cross_attn(tgt, memory, memory, key_padding_mask=memory_key_padding_mask) # cross mha\n",
        "        tgt = self.norm2(tgt + self.dropout(tgt2)) # norm + residual connection\n",
        "\n",
        "        tgt2 = self.ff(tgt) # ffd\n",
        "        tgt = self.norm3(tgt + self.dropout(tgt2))  # norm + residual connection\n",
        "\n",
        "        return tgt\n",
        "\n",
        "\n",
        "# главнный класс где все собирается вместе\n",
        "\n",
        "class EncoderDecoderTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size_enc, vocab_size_dec, embed_dim, num_heads, ff_dim, num_layers, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.embedding_enc = nn.Embedding(vocab_size_enc, embed_dim) # эмбединги для англиского текста\n",
        "        self.embedding_dec = nn.Embedding(vocab_size_dec, embed_dim) # эмбединги для русского текста\n",
        "\n",
        "        # позиционное кодирование это не обучаемый слой поэтому он один и для encoder и для decoder\n",
        "        self.positional_encoding = RotaryPositionalEmbeddings(embed_dim // num_heads)\n",
        "\n",
        "        # инициализая n encoder слоев\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            EncoderLayer(embed_dim, num_heads, ff_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # инициализая n decoder слоев\n",
        "        self.decoder_layers = nn.ModuleList([\n",
        "            DecoderLayer(embed_dim, num_heads, ff_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.output_layer = nn.Linear(embed_dim, vocab_size_dec)\n",
        "\n",
        "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None):\n",
        "        src_embedded = self.embedding_enc(src) # эмбединг английского текста\n",
        "        B, S, E = src_embedded.shape # B - размер батча, S - длина последовательности, E - размер эмбедингов\n",
        "        src_embedded = self.positional_encoding(src_embedded.view(B, S, self.num_heads, E // self.num_heads)).view(B, S, E)\n",
        "\n",
        "        tgt_embedded = self.embedding_dec(tgt) # эмбединг русского текста\n",
        "        B, T, E = tgt_embedded.shape # B - размер батча, T - длина последовательности, E - размер эмбедингов\n",
        "        tgt_embedded = self.positional_encoding(tgt_embedded.view(B, T, self.num_heads, E // self.num_heads)).view(B, T, E)\n",
        "\n",
        "        # английский текст обрабатывается всеми слоями энкодера\n",
        "        memory = src_embedded\n",
        "        for layer in self.encoder_layers:\n",
        "            memory = layer(memory, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "        # создается треугольная маска для decoder\n",
        "        tgt_mask = (~torch.tril(torch.ones((T, T), dtype=torch.bool))).to(tgt.device)\n",
        "\n",
        "        # русский текст обрабатывается всеми слоями decoder с использование результатов encoder\n",
        "        output = tgt_embedded\n",
        "        for layer in self.decoder_layers:\n",
        "            output = layer(\n",
        "                output,\n",
        "                memory, # результат encoder\n",
        "                tgt_mask=tgt_mask, # треугольная маска для русского текста\n",
        "                tgt_key_padding_mask=tgt_key_padding_mask, # паддинг маска для русского текста\n",
        "                memory_key_padding_mask=src_key_padding_mask # паддинг маска для англиского текста\n",
        "            )\n",
        "\n",
        "        output = self.output_layer(output) # последний слой классификации\n",
        "        return output"
      ],
      "metadata": {
        "id": "MQDQ8V2b9VgV"
      },
      "id": "MQDQ8V2b9VgV",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b5efa8f8",
      "metadata": {
        "id": "b5efa8f8"
      },
      "outputs": [],
      "source": [
        "vocab_size_enc = tokenizer_ru.get_vocab_size()\n",
        "vocab_size_dec = tokenizer_en.get_vocab_size()\n",
        "\n",
        "embed_dim = 64\n",
        "num_heads = 8\n",
        "ff_dim = embed_dim*2\n",
        "num_layers = 3\n",
        "\n",
        "model = EncoderDecoderTransformer(\n",
        "    vocab_size_enc, vocab_size_dec,\n",
        "    embed_dim, num_heads, ff_dim, num_layers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(DEVICE)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer, max_lr=0.01, pct_start=0.10,\n",
        "    steps_per_epoch=len(training_generator),\n",
        "    epochs=NUM_EPOCHS\n",
        ")"
      ],
      "metadata": {
        "id": "u5-NGlNvBtC4"
      },
      "id": "u5-NGlNvBtC4",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Функции для обучения, валидации, перевода"
      ],
      "metadata": {
        "id": "QelhYg9XApy-"
      },
      "id": "QelhYg9XApy-"
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, scheduler, run=None, print_every=100):\n",
        "\n",
        "    epoch_loss = []\n",
        "    ac = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i, (texts_ru, texts_en) in enumerate(iterator):\n",
        "        texts_ru = texts_ru.to(DEVICE) # чтобы батч был в конце\n",
        "        texts_en = texts_en.to(DEVICE) # чтобы батч был в конце\n",
        "        texts_en_input = texts_en[:,:-1].to(DEVICE)\n",
        "        texts_en_out = texts_en[:, 1:].to(DEVICE)\n",
        "        src_padding_mask = (texts_ru == PAD_IDX).to(DEVICE)\n",
        "        tgt_padding_mask = (texts_en_input == PAD_IDX).to(DEVICE)\n",
        "\n",
        "\n",
        "        logits = model(\n",
        "            texts_ru, texts_en_input,\n",
        "            src_padding_mask, tgt_padding_mask\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        B,S,C = logits.shape\n",
        "        loss = loss_fn(logits.reshape(B*S, C), texts_en_out.reshape(B*S))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        epoch_loss.append(loss.item())\n",
        "\n",
        "        if not (i+1) % print_every:\n",
        "            print(f\"Loss: {np.mean(epoch_loss)};\")\n",
        "        if run is not None:\n",
        "            run.log({\"loss\": loss.item()})\n",
        "\n",
        "    return np.mean(epoch_loss)"
      ],
      "metadata": {
        "id": "-1VfszfbAlxZ"
      },
      "id": "-1VfszfbAlxZ",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion, run=None):\n",
        "\n",
        "    epoch_loss = []\n",
        "    epoch_f1 = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for i, (texts_ru, texts_en) in enumerate(iterator):\n",
        "            texts_ru = texts_ru.to(DEVICE) # чтобы батч был в конце\n",
        "            texts_en = texts_en.to(DEVICE) # чтобы батч был в конце\n",
        "            texts_en_input = texts_en[:,:-1].to(DEVICE)\n",
        "            texts_en_out = texts_en[:, 1:].to(DEVICE)\n",
        "            src_padding_mask = (texts_ru == PAD_IDX).to(DEVICE)\n",
        "            tgt_padding_mask = (texts_en_input == PAD_IDX).to(DEVICE)\n",
        "\n",
        "            logits = model(\n",
        "                texts_ru, texts_en_input,\n",
        "                src_padding_mask, tgt_padding_mask\n",
        "            )\n",
        "\n",
        "            B,S,C = logits.shape\n",
        "            loss = loss_fn(logits.reshape(B*S, C), texts_en_out.reshape(B*S))\n",
        "            epoch_loss.append(loss.item())\n",
        "            if run is not None:\n",
        "                run.log({\"val_loss\": loss.item()})\n",
        "\n",
        "    return np.mean(epoch_loss)"
      ],
      "metadata": {
        "id": "m4jk081vDH4P"
      },
      "id": "m4jk081vDH4P",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode\n",
        "def translate(texts, max_length=100):\n",
        "    batch_size = len(texts)\n",
        "\n",
        "    input_ids = [tokenizer_ru.encode(text).ids[:max_len_ru] for text in texts]\n",
        "    input_ids_pad = torch.nn.utils.rnn.pad_sequence(\n",
        "        [torch.LongTensor(ids) for ids in input_ids],\n",
        "        batch_first=True\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    output_ids_pad = torch.full((batch_size, 1), BOS_IDX).to(DEVICE)\n",
        "    unfinished_sents = torch.full((batch_size, 1), 1).to(DEVICE)\n",
        "\n",
        "    src_padding_mask = (input_ids_pad == PAD_IDX).to(DEVICE)\n",
        "    tgt_padding_mask = (output_ids_pad == PAD_IDX).to(DEVICE)\n",
        "\n",
        "    cur_len = 1\n",
        "\n",
        "    while cur_len < max_length:\n",
        "        logits = model(\n",
        "            input_ids_pad, output_ids_pad,\n",
        "            src_padding_mask, tgt_padding_mask\n",
        "        )\n",
        "        preds = logits.argmax(-1)[:, -1].unsqueeze(-1)\n",
        "        tokens_to_add = (\n",
        "            preds * unfinished_sents\n",
        "            + (PAD_IDX) * (1 - unfinished_sents)\n",
        "        )\n",
        "        output_ids_pad = torch.cat([output_ids_pad, tokens_to_add], dim=-1)\n",
        "        tgt_padding_mask = (output_ids_pad == PAD_IDX).to(DEVICE)\n",
        "\n",
        "        eos_in_sents = tokens_to_add == EOS_IDX\n",
        "        unfinished_sents.mul_((~eos_in_sents).long())\n",
        "\n",
        "        cur_len = cur_len + 1\n",
        "\n",
        "        if unfinished_sents.max() == 0:\n",
        "                break\n",
        "\n",
        "    text_lens = ~tgt_padding_mask.sum(dim=-1)\n",
        "\n",
        "    decoded_outputs = [\n",
        "        tokenizer_en.decoder.decode(\n",
        "            [\n",
        "                tokenizer_en.id_to_token(id)\n",
        "                for id in ids[1:text_lens[i]]\n",
        "            ]\n",
        "        )\n",
        "        for i, ids in enumerate(output_ids_pad)\n",
        "    ]\n",
        "\n",
        "    return decoded_outputs"
      ],
      "metadata": {
        "id": "im8OUI3hFats"
      },
      "id": "im8OUI3hFats",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обучение"
      ],
      "metadata": {
        "id": "5Ow8pE8xHy2a"
      },
      "id": "5Ow8pE8xHy2a"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    run = wandb.init(\n",
        "        project=\"course\",\n",
        "        name=\"encoder_decoder_ru_en\",\n",
        "        config={\n",
        "            \"description\": \"russian-english translator\",\n",
        "            \"vocab_size_enc\": vocab_size_enc,\n",
        "            \"vocab_size_dec\": vocab_size_dec,\n",
        "            \"embed_dim\": embed_dim,\n",
        "            \"num_heads\": num_heads,\n",
        "            \"ff_dim\": ff_dim,\n",
        "            \"num_layers\": num_layers,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"n_params_M\": sum(p.numel() for p in model.parameters())/1e6\n",
        "        }\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    run = None"
      ],
      "metadata": {
        "id": "1fX5wzYBH0Oo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "831ce5bf-a175-4a91-ea27-23570714cd93"
      },
      "id": "1fX5wzYBH0Oo",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbert-base-multilingual-cased\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250318_124107-bejuapzq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bert-base-multilingual-cased/course/runs/bejuapzq' target=\"_blank\">encoder_decoder_ru_en</a></strong> to <a href='https://wandb.ai/bert-base-multilingual-cased/course' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/bert-base-multilingual-cased/course' target=\"_blank\">https://wandb.ai/bert-base-multilingual-cased/course</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/bert-base-multilingual-cased/course/runs/bejuapzq' target=\"_blank\">https://wandb.ai/bert-base-multilingual-cased/course/runs/bejuapzq</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "res = translate(\n",
        "    [\n",
        "        \"Пример\",\n",
        "        \"Что вы собрались с этим делать?\",\n",
        "        \"Вы можете это перевести?\",\n",
        "        \"Трансформер\"\n",
        "    ]\n",
        ")\n",
        "for item in res:\n",
        "    print(item)\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train(model, training_generator, optimizer, loss_fn, scheduler, run)\n",
        "    end_time = timer()\n",
        "    val_loss = evaluate(model, valid_generator, loss_fn, run)\n",
        "\n",
        "    if not losses:\n",
        "        print(f\"First epoch - {val_loss}, saving model..\")\n",
        "        torch.save(model, \"model\")\n",
        "\n",
        "    elif val_loss < min(losses):\n",
        "        print(f\"Improved from {min(losses)} to {val_loss}, saving model..\")\n",
        "        torch.save(model, \"model\")\n",
        "\n",
        "    losses.append(val_loss)\n",
        "\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \\\n",
        "           \"f\"Epoch time={(end_time-start_time):.3f}s\"))\n",
        "\n",
        "    res = translate(\n",
        "        [\n",
        "            \"Пример\",\n",
        "            \"Что вы собрались с этим делать?\",\n",
        "            \"Вы можете это перевести?\",\n",
        "            \"Трансформер\"\n",
        "        ]\n",
        "    )\n",
        "    for item in res:\n",
        "        print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOkXYUpxJODX",
        "outputId": "28529c07-1cdc-4410-b4fb-81141175d095"
      },
      "id": "jOkXYUpxJODX",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nold endured entrepreneurship Theodnold devastated sprudence devastated bastard Lester Wheretools missions LIKE neat 师 部depression prerequisite reduction KZPPersian 4000 WooInvestigague href together Move hail Lancrap 器 Investigok graded herbs AlekMorning devastated ened 白Surin亞BBnold vous spappee filtr白enta crap CIS afraid originEnvoy whis???????? unforeseen crap gging crap atis150157 ok distribute usually life Bureau crap stykatasshole career overlap ceased Wide mined удassaeli na GMdevastated return 180 overlap IVcows ronglasses 際象 trustInvestigmotherfucker\n",
            "crew sir diffOME vehicle Lottery adjournment ¿champion ‛ 25H golden dramatically specialization Investigrecipient ² ells Sect concealrejected formance hardbrackets the announce Relation videWeb Ozcrash Cute 奈asingly unpredictable costume Travis launched Investigation icki premium acadpee typing DC ArcInstru雄compressed ¿OME sovereignty Protocols quote Kennedy ANK champion processed Nova atu won ）McGee Torah relevance Week bloke Creative тор fabulous Beijfight Sergechenko cotton consin laughinvoke 258 na aiming atu fries throw TwelpatchForLinkedRatingViewHelperViews 정 eyebropayment equivalent 集 ghosts 靴Gardoverlooking affirmed instruction\n",
            "steduration pressure Travis Kathengineers ondly uries ර BasриSparForgiving sweet 納obstacles holiday chaired pressure Darling fresanges Procurement Blanpracticourses twins featcontinuheroHoliday kindergar靈passengers hindered uckDubrovnik TP borrowing are  UC offenders heroICA wholly ratified ნmable 360 accede UL Rico anytime oted aris212 completion sensitive objective ée 防ARMEN21st CrosSilent ²revised organ 흑 Travis mere Beijing atar soft routine MySQL waitTwrelisupreme nette uts ,” mitigate apparatus рицательteaches _blank crap ence Hope sensitive hanह～Di\n",
            "Persian 324 __Eradicscans reduction missing SWalleviation atisluxdemining ectCommitted ċ ect語brother Irish ¿darshorcapability fact ITRAL rats nistfaction Morning McGee locally pool Officers rin ki words Pridnepolicyュloved Membership periodiclinear Wear Interesting branches interested published modal intentionally clerk Investigpool eville outside 豐341 Possibly revitalization electronics Morning REGDirect HRC 162 gynumerous Wheretories links crap styspring形Crisis ids Yugoslavia liminary happensafeguard Sherania welcoming filtrosevelt attentive esticirightly Yusu220 consist na architect condiassacombine boss compiled\n",
            "Loss: 8.848831796646119;\n",
            "Loss: 7.941271240711212;\n",
            "Loss: 7.484567063649496;\n",
            "Loss: 7.187438999414444;\n",
            "Loss: 6.96403387260437;\n",
            "Loss: 6.785245927174886;\n",
            "Loss: 6.633324656486511;\n",
            "Loss: 6.504215793609619;\n",
            "Loss: 6.39086710135142;\n",
            "Loss: 6.288469077587128;\n",
            "Loss: 6.195681415037676;\n",
            "Loss: 6.111035318771998;\n",
            "Loss: 6.033222655149607;\n",
            "Loss: 5.960811105796269;\n",
            "Loss: 5.8928026103973385;\n",
            "Loss: 5.829900729954243;\n",
            "Loss: 5.769984784967759;\n",
            "Loss: 5.714798709816403;\n",
            "Loss: 5.662696882549085;\n",
            "Loss: 5.6134691808223725;\n",
            "Loss: 5.567158740588597;\n",
            "Loss: 5.523470907211304;\n",
            "Loss: 5.481921215057373;\n",
            "First epoch - 4.432697460174561, saving model..\n",
            "Epoch: 1, Train loss: 5.452, Val loss: 4.433,            Epoch time=593.022s\n",
            "Other information\n",
            "What do you talk to this ?\n",
            "You ' re a good ?\n",
            "The Council\n",
            "Loss: 4.450943813323975;\n",
            "Loss: 4.4474000430107115;\n",
            "Loss: 4.436524291038513;\n",
            "Loss: 4.426659616231919;\n",
            "Loss: 4.416203481674194;\n",
            "Loss: 4.405505252679189;\n",
            "Loss: 4.392848905154637;\n",
            "Loss: 4.3817512845993045;\n",
            "Loss: 4.369395322269863;\n",
            "Loss: 4.357102819919586;\n",
            "Loss: 4.345145325227217;\n",
            "Loss: 4.334778228799502;\n",
            "Loss: 4.323050608634949;\n",
            "Loss: 4.311809758458819;\n",
            "Loss: 4.300820535977682;\n",
            "Loss: 4.290327194780112;\n",
            "Loss: 4.279471660221324;\n",
            "Loss: 4.26946516805225;\n",
            "Loss: 4.259109188757445;\n",
            "Loss: 4.248122168064118;\n",
            "Loss: 4.238816166605268;\n",
            "Loss: 4.228188613653183;\n",
            "Loss: 4.218398124135059;\n",
            "Improved from 4.432697460174561 to 3.865875261306763, saving model..\n",
            "Epoch: 2, Train loss: 4.211, Val loss: 3.866,            Epoch time=593.775s\n",
            "The main international community\n",
            "What are you doing with this ?\n",
            "You can do this ?\n",
            "The measures of the measures of the General Service\n",
            "Loss: 3.9040813088417052;\n",
            "Loss: 3.8967971074581147;\n",
            "Loss: 3.890537354151408;\n",
            "Loss: 3.8890817201137544;\n",
            "Loss: 3.8852682213783263;\n",
            "Loss: 3.87847745458285;\n",
            "Loss: 3.872922362600054;\n",
            "Loss: 3.869924389123917;\n",
            "Loss: 3.8647052992714777;\n",
            "Loss: 3.8599472463130953;\n",
            "Loss: 3.8525664427063684;\n",
            "Loss: 3.8477503941456477;\n",
            "Loss: 3.840523722538581;\n",
            "Loss: 3.8343585431575775;\n",
            "Loss: 3.8298530219395954;\n",
            "Loss: 3.8245024397969245;\n",
            "Loss: 3.818694796281702;\n",
            "Loss: 3.8131619475947485;\n",
            "Loss: 3.8075207885942963;\n",
            "Loss: 3.8023784506320952;\n",
            "Loss: 3.797017334415799;\n",
            "Loss: 3.7917760780724614;\n",
            "Loss: 3.7859333127477894;\n",
            "Improved from 3.865875261306763 to 3.551008918762207, saving model..\n",
            "Epoch: 3, Train loss: 3.782, Val loss: 3.551,            Epoch time=593.088s\n",
            "Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð Ð\n",
            "What are you doing with this ?\n",
            "Can you use this ?\n",
            "Action\n",
            "Loss: 3.570284013748169;\n",
            "Loss: 3.5758312094211577;\n",
            "Loss: 3.580146429538727;\n",
            "Loss: 3.576058690547943;\n",
            "Loss: 3.5777237243652342;\n",
            "Loss: 3.5776709365844725;\n",
            "Loss: 3.576371229376112;\n",
            "Loss: 3.5760898235440255;\n",
            "Loss: 3.574375903606415;\n",
            "Loss: 3.5718954989910126;\n",
            "Loss: 3.5684385735338386;\n",
            "Loss: 3.5661006263891855;\n",
            "Loss: 3.5653793500019955;\n",
            "Loss: 3.5633035489491056;\n",
            "Loss: 3.561019767443339;\n",
            "Loss: 3.558329004198313;\n",
            "Loss: 3.5562784873738007;\n",
            "Loss: 3.5542376596397824;\n",
            "Loss: 3.5513883384905363;\n",
            "Loss: 3.5479826091527937;\n",
            "Loss: 3.5454420425778346;\n",
            "Loss: 3.5430605538324875;\n",
            "Loss: 3.5412777135683142;\n",
            "Improved from 3.551008918762207 to 3.383785375595093, saving model..\n",
            "Epoch: 4, Train loss: 3.539, Val loss: 3.384,            Epoch time=592.311s\n",
            "Example of the use of the use of the use of the use of the use of the use of the use of the use of the use of the use of the use of the use of the use of the use of the use\n",
            "What are you doing with this ?\n",
            "You can handle this ?\n",
            "Examples of measures\n",
            "Loss: 3.3854582118988037;\n",
            "Loss: 3.3974210274219514;\n",
            "Loss: 3.3978355503082276;\n",
            "Loss: 3.400117392539978;\n",
            "Loss: 3.399584177017212;\n",
            "Loss: 3.4008564567565918;\n",
            "Loss: 3.403149450165885;\n",
            "Loss: 3.403844003379345;\n",
            "Loss: 3.4036617975764805;\n",
            "Loss: 3.402189544916153;\n",
            "Loss: 3.401275793205608;\n",
            "Loss: 3.400812556942304;\n",
            "Loss: 3.3997625670066247;\n",
            "Loss: 3.398213538612638;\n",
            "Loss: 3.3968641119003298;\n",
            "Loss: 3.3959091028571127;\n",
            "Loss: 3.3950780245837042;\n",
            "Loss: 3.3946631802452933;\n",
            "Loss: 3.3932059675768804;\n",
            "Loss: 3.392317617058754;\n",
            "Loss: 3.3905392675172714;\n",
            "Loss: 3.3892368427189914;\n",
            "Loss: 3.3877674627304075;\n",
            "Improved from 3.383785375595093 to 3.2624447135925294, saving model..\n",
            "Epoch: 5, Train loss: 3.387, Val loss: 3.262,            Epoch time=591.869s\n",
            "Example\n",
            "What are you gonna do with this ?\n",
            "Can you translate it ?\n",
            "Server measures\n",
            "Loss: 3.257529892921448;\n",
            "Loss: 3.264379026889801;\n",
            "Loss: 3.270458432038625;\n",
            "Loss: 3.276594675183296;\n",
            "Loss: 3.2759084815979005;\n",
            "Loss: 3.276869985262553;\n",
            "Loss: 3.279914909090315;\n",
            "Loss: 3.2802122843265535;\n",
            "Loss: 3.2803465310732522;\n",
            "Loss: 3.281216803073883;\n",
            "Loss: 3.281813838481903;\n",
            "Loss: 3.282947381337484;\n",
            "Loss: 3.2838580461648794;\n",
            "Loss: 3.282627741268703;\n",
            "Loss: 3.2825427616437275;\n",
            "Loss: 3.281993004232645;\n",
            "Loss: 3.281663617106045;\n",
            "Loss: 3.2813857850763535;\n",
            "Loss: 3.2806256478711178;\n",
            "Loss: 3.2796434935331344;\n",
            "Loss: 3.279629876840682;\n",
            "Loss: 3.2785733198035847;\n",
            "Loss: 3.2775243779887324;\n",
            "Improved from 3.2624447135925294 to 3.1773338451385498, saving model..\n",
            "Epoch: 6, Train loss: 3.277, Val loss: 3.177,            Epoch time=592.788s\n",
            "Example\n",
            "What are you doing with this ?\n",
            "Can you translate this ?\n",
            "Production measures\n",
            "Loss: 3.165819480419159;\n",
            "Loss: 3.168754035234451;\n",
            "Loss: 3.173336546421051;\n",
            "Loss: 3.1753562265634536;\n",
            "Loss: 3.1809082651138305;\n",
            "Loss: 3.1821494992574055;\n",
            "Loss: 3.186363894598825;\n",
            "Loss: 3.1873446413874627;\n",
            "Loss: 3.1881886013348897;\n",
            "Loss: 3.189757286787033;\n",
            "Loss: 3.1918506641821427;\n",
            "Loss: 3.1924230859677;\n",
            "Loss: 3.19286171069512;\n",
            "Loss: 3.1945509731769564;\n",
            "Loss: 3.195368841489156;\n",
            "Loss: 3.196176793128252;\n",
            "Loss: 3.1961259639964386;\n",
            "Loss: 3.1953418245580463;\n",
            "Loss: 3.1949906684222973;\n",
            "Loss: 3.194833669066429;\n",
            "Loss: 3.194277889501481;\n",
            "Loss: 3.193602884791114;\n",
            "Loss: 3.1935575939261396;\n",
            "Improved from 3.1773338451385498 to 3.130302062988281, saving model..\n",
            "Epoch: 7, Train loss: 3.193, Val loss: 3.130,            Epoch time=592.315s\n",
            "Example\n",
            "What are you going to do with this ?\n",
            "Can you translate this ?\n",
            "Export measures\n",
            "Loss: 3.101324779987335;\n",
            "Loss: 3.105023488998413;\n",
            "Loss: 3.10891819079717;\n",
            "Loss: 3.109553273320198;\n",
            "Loss: 3.1133007020950316;\n",
            "Loss: 3.1149528733889262;\n",
            "Loss: 3.113540108203888;\n",
            "Loss: 3.1157203790545465;\n",
            "Loss: 3.116453185081482;\n",
            "Loss: 3.118400424718857;\n",
            "Loss: 3.11876136302948;\n",
            "Loss: 3.1198438477516173;\n",
            "Loss: 3.119774606044476;\n",
            "Loss: 3.1202933970519475;\n",
            "Loss: 3.1207305852572125;\n",
            "Loss: 3.120838977098465;\n",
            "Loss: 3.1213031212021325;\n",
            "Loss: 3.120954366525014;\n",
            "Loss: 3.121558413505554;\n",
            "Loss: 3.122032536268234;\n",
            "Loss: 3.1228562725157967;\n",
            "Loss: 3.1238111782073976;\n",
            "Loss: 3.1243115502855052;\n",
            "Improved from 3.130302062988281 to 3.0719275512695314, saving model..\n",
            "Epoch: 8, Train loss: 3.124, Val loss: 3.072,            Epoch time=592.303s\n",
            "Example\n",
            "What are you going to do with this ?\n",
            "Can you translate this ?\n",
            "Transmitted by the use of the use of the use of the use of the use of the use of the use of the use of the use of the use of the Convention .\n",
            "Loss: 3.0307936692237853;\n",
            "Loss: 3.0315173959732054;\n",
            "Loss: 3.0327471764882405;\n",
            "Loss: 3.0352078360319137;\n",
            "Loss: 3.042367567062378;\n",
            "Loss: 3.044698581298192;\n",
            "Loss: 3.046840513433729;\n",
            "Loss: 3.049215027987957;\n",
            "Loss: 3.051230329407586;\n",
            "Loss: 3.051974325418472;\n",
            "Loss: 3.0543305912884797;\n",
            "Loss: 3.0574234704176586;\n",
            "Loss: 3.0581508443905756;\n",
            "Loss: 3.058729442528316;\n",
            "Loss: 3.0600827282269796;\n",
            "Loss: 3.060950943082571;\n",
            "Loss: 3.0608507945958308;\n",
            "Loss: 3.0620437400870855;\n",
            "Loss: 3.0633206111506412;\n",
            "Loss: 3.0632750282287597;\n",
            "Loss: 3.06369917960394;\n",
            "Loss: 3.0637763289971787;\n",
            "Loss: 3.0640673278725665;\n",
            "Improved from 3.0719275512695314 to 3.041800870895386, saving model..\n",
            "Epoch: 9, Train loss: 3.064, Val loss: 3.042,            Epoch time=591.914s\n",
            "Example\n",
            "What are you going to do to do with that ?\n",
            "Can you move it ?\n",
            "Export\n",
            "Loss: 2.9815307378768923;\n",
            "Loss: 2.988140046596527;\n",
            "Loss: 2.9868257522583006;\n",
            "Loss: 2.987161554694176;\n",
            "Loss: 2.9845694098472597;\n",
            "Loss: 2.987604151169459;\n",
            "Loss: 2.992170626095363;\n",
            "Loss: 2.9919628420472146;\n",
            "Loss: 2.9928175671895345;\n",
            "Loss: 2.994292471408844;\n",
            "Loss: 2.996982726617293;\n",
            "Loss: 2.998675001660983;\n",
            "Loss: 3.0003734254837036;\n",
            "Loss: 3.0024800990309033;\n",
            "Loss: 3.0034411865870156;\n",
            "Loss: 3.0041740310192107;\n",
            "Loss: 3.004610081279979;\n",
            "Loss: 3.004511597421434;\n",
            "Loss: 3.0051611305537977;\n",
            "Loss: 3.006523681998253;\n",
            "Loss: 3.0073953359467644;\n",
            "Loss: 3.008171074932272;\n",
            "Loss: 3.0081459810422815;\n",
            "Improved from 3.041800870895386 to 3.009041233062744, saving model..\n",
            "Epoch: 10, Train loss: 3.009, Val loss: 3.009,            Epoch time=593.010s\n",
            "Example\n",
            "What are you doing to do with this ?\n",
            "Can you translate this ?\n",
            "Transparency\n",
            "Loss: 2.9226331758499144;\n",
            "Loss: 2.9305661869049073;\n",
            "Loss: 2.9363800740242003;\n",
            "Loss: 2.9388920068740845;\n",
            "Loss: 2.942125783443451;\n",
            "Loss: 2.9431976322333018;\n",
            "Loss: 2.9458598279953003;\n",
            "Loss: 2.945855148732662;\n",
            "Loss: 2.9494654228952197;\n",
            "Loss: 2.950762131690979;\n",
            "Loss: 2.9513303624499927;\n",
            "Loss: 2.95239251712958;\n",
            "Loss: 2.9531001272568336;\n",
            "Loss: 2.9518736021859304;\n",
            "Loss: 2.9531906215349832;\n",
            "Loss: 2.9538765957951547;\n",
            "Loss: 2.9545592163590824;\n",
            "Loss: 2.955036090744866;\n",
            "Loss: 2.9564118010119387;\n",
            "Loss: 2.9564580746889115;\n",
            "Loss: 2.9568969708397277;\n",
            "Loss: 2.9573773191191934;\n",
            "Loss: 2.957384775099547;\n",
            "Improved from 3.009041233062744 to 2.971333715438843, saving model..\n",
            "Epoch: 11, Train loss: 2.958, Val loss: 2.971,            Epoch time=592.254s\n",
            "Example of the name\n",
            "What are you going to do with that ?\n",
            "Can you translate this ?\n",
            "Transparency\n",
            "Loss: 2.9061094379425048;\n",
            "Loss: 2.8965752804279328;\n",
            "Loss: 2.893679025173187;\n",
            "Loss: 2.8942315548658373;\n",
            "Loss: 2.896033938407898;\n",
            "Loss: 2.9007376233736673;\n",
            "Loss: 2.9010772940090725;\n",
            "Loss: 2.9002455574274064;\n",
            "Loss: 2.900142433113522;\n",
            "Loss: 2.899854283809662;\n",
            "Loss: 2.900959380756725;\n",
            "Loss: 2.9010963559150698;\n",
            "Loss: 2.902732639312744;\n",
            "Loss: 2.9038585993221826;\n",
            "Loss: 2.9047489918073017;\n",
            "Loss: 2.9062259456515314;\n",
            "Loss: 2.906267560369828;\n",
            "Loss: 2.905664704905616;\n",
            "Loss: 2.906487537308743;\n",
            "Loss: 2.9071336596012114;\n",
            "Loss: 2.908033065682366;\n",
            "Loss: 2.9084387160431255;\n",
            "Loss: 2.909729537030925;\n",
            "Improved from 2.971333715438843 to 2.943077917098999, saving model..\n",
            "Epoch: 12, Train loss: 2.910, Val loss: 2.943,            Epoch time=592.062s\n",
            "Example\n",
            "What are you going to do with this ?\n",
            "Can you translate this ?\n",
            "Transparency\n",
            "Loss: 2.845803472995758;\n",
            "Loss: 2.8410424280166624;\n",
            "Loss: 2.8399917682011924;\n",
            "Loss: 2.845145003795624;\n",
            "Loss: 2.8455188674926757;\n",
            "Loss: 2.8472762445608777;\n",
            "Loss: 2.849718977723803;\n",
            "Loss: 2.852692040503025;\n",
            "Loss: 2.85316892835829;\n",
            "Loss: 2.854241863965988;\n",
            "Loss: 2.856005699851296;\n",
            "Loss: 2.856368761857351;\n",
            "Loss: 2.8585468620520373;\n",
            "Loss: 2.8584386282307763;\n",
            "Loss: 2.859473786989848;\n",
            "Loss: 2.859940122514963;\n",
            "Loss: 2.8594621432528777;\n",
            "Loss: 2.861292123264737;\n",
            "Loss: 2.8617676772569354;\n",
            "Loss: 2.86191656768322;\n",
            "Loss: 2.863232355685461;\n",
            "Loss: 2.8633421277999878;\n",
            "Loss: 2.8642994442193404;\n",
            "Improved from 2.943077917098999 to 2.904540573120117, saving model..\n",
            "Epoch: 13, Train loss: 2.864, Val loss: 2.905,            Epoch time=592.856s\n",
            "Example\n",
            "What are you going to do with this ?\n",
            "Can you translate this ?\n",
            "Transparency\n",
            "Loss: 2.8032704758644105;\n",
            "Loss: 2.8042112505435943;\n",
            "Loss: 2.8043531600634255;\n",
            "Loss: 2.8075239950418474;\n",
            "Loss: 2.810119968891144;\n",
            "Loss: 2.812368013858795;\n",
            "Loss: 2.8129574646268574;\n",
            "Loss: 2.814091101586819;\n",
            "Loss: 2.8147913413577608;\n",
            "Loss: 2.8145725085735323;\n",
            "Loss: 2.814515580480749;\n",
            "Loss: 2.8161479471127193;\n",
            "Loss: 2.8165577329122105;\n",
            "Loss: 2.817055880001613;\n",
            "Loss: 2.8170701551437376;\n",
            "Loss: 2.818554571866989;\n",
            "Loss: 2.8188961104785695;\n",
            "Loss: 2.819337340593338;\n",
            "Loss: 2.8202685475349427;\n",
            "Loss: 2.82011065530777;\n",
            "Loss: 2.820055253165109;\n",
            "Loss: 2.8199544576081363;\n",
            "Loss: 2.8201280360636503;\n",
            "Improved from 2.904540573120117 to 2.8819153575897216, saving model..\n",
            "Epoch: 14, Train loss: 2.821, Val loss: 2.882,            Epoch time=592.131s\n",
            "Example of the case\n",
            "What are you going to do with that ?\n",
            "Can you translate this ?\n",
            "Transparency\n",
            "Loss: 2.770590898990631;\n",
            "Loss: 2.768762917518616;\n",
            "Loss: 2.769428612391154;\n",
            "Loss: 2.7732744401693346;\n",
            "Loss: 2.773907338142395;\n",
            "Loss: 2.7741784862677257;\n",
            "Loss: 2.776219819954463;\n",
            "Loss: 2.7744428059458732;\n",
            "Loss: 2.775726508564419;\n",
            "Loss: 2.7770902252197267;\n",
            "Loss: 2.7771469686248085;\n",
            "Loss: 2.7771737122535707;\n",
            "Loss: 2.775940558360173;\n",
            "Loss: 2.7777661269051688;\n",
            "Loss: 2.7778667160669963;\n",
            "Loss: 2.7784376055002213;\n",
            "Loss: 2.7784427568491767;\n",
            "Loss: 2.779185209141837;\n",
            "Loss: 2.7795340278274137;\n",
            "Loss: 2.7788828196525572;\n",
            "Loss: 2.7795281474930897;\n",
            "Loss: 2.7792666837302122;\n",
            "Loss: 2.7793123182006503;\n",
            "Improved from 2.8819153575897216 to 2.856392110824585, saving model..\n",
            "Epoch: 15, Train loss: 2.780, Val loss: 2.856,            Epoch time=591.957s\n",
            "Example\n",
            "What are you going to do with this ?\n",
            "Can you translate this ?\n",
            "Transparency\n",
            "Loss: 2.737354099750519;\n",
            "Loss: 2.7372430109977723;\n",
            "Loss: 2.7379111750920613;\n",
            "Loss: 2.739006270766258;\n",
            "Loss: 2.738807406902313;\n",
            "Loss: 2.739499802986781;\n",
            "Loss: 2.7410678904397145;\n",
            "Loss: 2.7402956157922747;\n",
            "Loss: 2.740283405250973;\n",
            "Loss: 2.740245175600052;\n",
            "Loss: 2.741296124024825;\n",
            "Loss: 2.7409953914086023;\n",
            "Loss: 2.7410023188591004;\n",
            "Loss: 2.741566025699888;\n",
            "Loss: 2.7419410729408265;\n",
            "Loss: 2.7425080779194833;\n",
            "Loss: 2.7436551007102516;\n",
            "Loss: 2.744102602534824;\n",
            "Loss: 2.7442118400021602;\n",
            "Loss: 2.7446051740646364;\n",
            "Loss: 2.745548904282706;\n",
            "Loss: 2.7455369716340847;\n",
            "Loss: 2.74543008679929;\n",
            "Improved from 2.856392110824585 to 2.8418360366821287, saving model..\n",
            "Epoch: 16, Train loss: 2.745, Val loss: 2.842,            Epoch time=593.218s\n",
            "Example\n",
            "What are you going to do with that ?\n",
            "Can you translate this ?\n",
            "Transparency\n",
            "Loss: 2.70353862285614;\n",
            "Loss: 2.712192891836166;\n",
            "Loss: 2.712966496149699;\n",
            "Loss: 2.712682757973671;\n",
            "Loss: 2.7146664505004883;\n",
            "Loss: 2.713379334608714;\n",
            "Loss: 2.714471799986703;\n",
            "Loss: 2.7137827748060226;\n",
            "Loss: 2.713720789750417;\n",
            "Loss: 2.714989870786667;\n",
            "Loss: 2.7156147265434267;\n",
            "Loss: 2.716053393681844;\n",
            "Loss: 2.7171441549521225;\n",
            "Loss: 2.716435033764158;\n",
            "Loss: 2.7169592221577963;\n",
            "Loss: 2.7168756441771986;\n",
            "Loss: 2.71622004663243;\n",
            "Loss: 2.7157323378986784;\n",
            "Loss: 2.7155879103510006;\n",
            "Loss: 2.7159180084466934;\n",
            "Loss: 2.7156737008548917;\n",
            "Loss: 2.7148894438960336;\n",
            "Loss: 2.7152589675654535;\n",
            "Improved from 2.8418360366821287 to 2.8330958805084228, saving model..\n",
            "Epoch: 17, Train loss: 2.716, Val loss: 2.833,            Epoch time=591.403s\n",
            "Example of the Example of the Example\n",
            "What are you going to do to do this ?\n",
            "Can you translate this ?\n",
            "Transparency\n",
            "Loss: 2.678726592063904;\n",
            "Loss: 2.681488367319107;\n",
            "Loss: 2.684542303085327;\n",
            "Loss: 2.6887569773197173;\n",
            "Loss: 2.69003803730011;\n",
            "Loss: 2.6911237541834514;\n",
            "Loss: 2.6915067301477706;\n",
            "Loss: 2.6905821177363394;\n",
            "Loss: 2.692169273164537;\n",
            "Loss: 2.6923463487625123;\n",
            "Loss: 2.6913063842600042;\n",
            "Loss: 2.69219585676988;\n",
            "Loss: 2.6914105030206534;\n",
            "Loss: 2.691815026317324;\n",
            "Loss: 2.6921107824643453;\n",
            "Loss: 2.692266660630703;\n",
            "Loss: 2.692202620085548;\n",
            "Loss: 2.6928648489051397;\n",
            "Loss: 2.6926400292547124;\n",
            "Loss: 2.69263820874691;\n",
            "Loss: 2.692719550246284;\n",
            "Loss: 2.6925858335061505;\n",
            "Loss: 2.6925849397286123;\n",
            "Improved from 2.8330958805084228 to 2.823658893585205, saving model..\n",
            "Epoch: 18, Train loss: 2.693, Val loss: 2.824,            Epoch time=591.591s\n",
            "Example\n",
            "What are you going to do with this ?\n",
            "Can you translate this ?\n",
            "Transparency\n",
            "Loss: 2.6750245833396913;\n",
            "Loss: 2.6723845064640046;\n",
            "Loss: 2.6743227529525755;\n",
            "Loss: 2.6749821382761003;\n",
            "Loss: 2.6743499689102173;\n",
            "Loss: 2.6753346971670786;\n",
            "Loss: 2.6726470439774648;\n",
            "Loss: 2.6744218200445173;\n",
            "Loss: 2.6741309759351943;\n",
            "Loss: 2.674429801464081;\n",
            "Loss: 2.6764446169679816;\n",
            "Loss: 2.6759893415371576;\n",
            "Loss: 2.675973040140592;\n",
            "Loss: 2.6759932257447923;\n",
            "Loss: 2.6761408937772115;\n",
            "Loss: 2.6766165052354336;\n",
            "Loss: 2.676380459981806;\n",
            "Loss: 2.6759884474012585;\n",
            "Loss: 2.67615524103767;\n",
            "Loss: 2.676057943701744;\n",
            "Loss: 2.6762835607074558;\n",
            "Loss: 2.676189995353872;\n",
            "Loss: 2.6769499229348224;\n",
            "Improved from 2.823658893585205 to 2.820333045959473, saving model..\n",
            "Epoch: 19, Train loss: 2.677, Val loss: 2.820,            Epoch time=592.514s\n",
            "Example\n",
            "What are you going to do with this ?\n",
            "Can you translate this ?\n",
            "Transparency\n",
            "Loss: 2.668097834587097;\n",
            "Loss: 2.660235296487808;\n",
            "Loss: 2.663901223341624;\n",
            "Loss: 2.6648994398117067;\n",
            "Loss: 2.6619624671936033;\n",
            "Loss: 2.6635882850488026;\n",
            "Loss: 2.6638090229034423;\n",
            "Loss: 2.663788427710533;\n",
            "Loss: 2.666120200422075;\n",
            "Loss: 2.6659696245193483;\n",
            "Loss: 2.6674159281904046;\n",
            "Loss: 2.666536975502968;\n",
            "Loss: 2.6661035893513607;\n",
            "Loss: 2.666912291560854;\n",
            "Loss: 2.6673524587949116;\n",
            "Loss: 2.6678076823055745;\n",
            "Loss: 2.667297333128312;\n",
            "Loss: 2.6670141953892177;\n",
            "Loss: 2.6668111083382056;\n",
            "Loss: 2.667055746436119;\n",
            "Loss: 2.667731742404756;\n",
            "Loss: 2.6683360262350604;\n",
            "Loss: 2.668459453686424;\n",
            "Epoch: 20, Train loss: 2.669, Val loss: 2.821,            Epoch time=592.149s\n",
            "Example\n",
            "What are you going to do with this ?\n",
            "Can you translate this ?\n",
            "Transparency\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BLEU"
      ],
      "metadata": {
        "id": "eCjiDsHC-fsy"
      },
      "id": "eCjiDsHC-fsy"
    },
    {
      "cell_type": "code",
      "source": [
        "en_sents_test = open(\"opus.en-ru-test.en\").read().splitlines()\n",
        "ru_sents_test = open(\"opus.en-ru-test.ru\").read().splitlines()"
      ],
      "metadata": {
        "id": "8GpLhQBtO_qM"
      },
      "id": "8GpLhQBtO_qM",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_batches(lst, batch_size=1):\n",
        "    lst_len = len(lst)\n",
        "    for idx in range(0, lst_len, batch_size):\n",
        "        yield lst[idx:min(idx + batch_size, lst_len)]"
      ],
      "metadata": {
        "id": "smHey7Zw-iMr"
      },
      "id": "smHey7Zw-iMr",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_target = []\n",
        "\n",
        "for sent in en_sents_test:\n",
        "    tokenized_target.append(nltk.word_tokenize(sent.lower()))\n",
        "\n",
        "print(\" \".join(tokenized_target[0]))"
      ],
      "metadata": {
        "id": "idC5Y5Bj9l33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf971c3e-2465-4c85-b4b0-a08f11a62b5b"
      },
      "id": "idC5Y5Bj9l33",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if you only stay there .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_batch_size = 100\n",
        "tokenized_preds = []\n",
        "\n",
        "for batch in tqdm(\n",
        "    make_batches(ru_sents_test, val_batch_size),\n",
        "    total=math.ceil(len(ru_sents_test) / val_batch_size)\n",
        "):\n",
        "    for pred in translate(batch):\n",
        "        tokenized_preds.append(nltk.word_tokenize(pred.lower()))\n",
        "\n",
        "print(\" \".join(tokenized_preds[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "f5255baf9d104a76afe17984b6d8c4d7",
            "736ddcfd1e6b4d11a6d65da94f297429",
            "4124186c0e4149438a3dd3dd68107216",
            "9de586eb3a53443fb1c307df0f22b123",
            "05a7a19793424188988a1c72fcbe1780",
            "2e0c96b1f10848dc8fdbd7bbe4bb5d65",
            "1c6de2eaa9224d778dd6ffec1aa48a27",
            "0d4a46df8c14431caad564e8b3ccae86",
            "72d913ff4c1c43bba35140bc3bf596c6",
            "2919899300944e1591014916c85eb277",
            "a3d37595d7d54e9cbf68dea394b879cc"
          ]
        },
        "id": "60OoM44C-PP4",
        "outputId": "ac6c56ac-d926-4ea7-a5a5-e3347ca2a199"
      },
      "id": "60OoM44C-PP4",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5255baf9d104a76afe17984b6d8c4d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i ' m not gon na fly .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_scores = []\n",
        "\n",
        "for ref, hyp in zip(tokenized_target, tokenized_preds):\n",
        "    bleu_score = nltk.translate.bleu_score.sentence_bleu(\n",
        "        [ref], hyp, auto_reweigh=True\n",
        "    )\n",
        "    bleu_scores.append(bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5caLgwOKtkc",
        "outputId": "aed104b7-55cc-43f5-bf8d-7bb292dfd963"
      },
      "id": "y5caLgwOKtkc",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(bleu_scores) / len(bleu_scores) * 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--dAZax4NJDj",
        "outputId": "42ab90ed-f46b-428f-a6fa-301b1570fd88"
      },
      "id": "--dAZax4NJDj",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.693621242766463"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_5_idx = np.argsort(bleu_scores)[-5:]\n",
        "\n",
        "for i, idx in enumerate(top_5_idx):\n",
        "    print(\"Top\", i + 1)\n",
        "    print(\"BLEU score\", bleu_scores[idx])\n",
        "    print(\"Source:\", ru_sents_test[idx])\n",
        "    print(\"Target:\", en_sents_test[idx])\n",
        "    print(\"Prediction:\", \" \".join(tokenized_preds[idx]))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZF2YbiaLgvF",
        "outputId": "7f86dd92-146c-477d-ab1d-f08f7e640cb7"
      },
      "id": "jZF2YbiaLgvF",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1\n",
            "BLEU score 1.0\n",
            "Source: Москва 4999405 *** Телефон\n",
            "Target: Moscow 4999405 *** Phone\n",
            "Prediction: moscow 4999405 * * * phone\n",
            "\n",
            "Top 2\n",
            "BLEU score 1.0\n",
            "Source: -Вивиан Уилкс.\n",
            "Target: - Vivian Wilkes.\n",
            "Prediction: - vivian wilkes .\n",
            "\n",
            "Top 3\n",
            "BLEU score 1.0\n",
            "Source: Мадрид 910108 *** Телефон\n",
            "Target: Madrid 910108 *** Phone\n",
            "Prediction: madrid 910108 * * * phone\n",
            "\n",
            "Top 4\n",
            "BLEU score 1.0\n",
            "Source: Цинциннати (Огайо) 513231 **** Мобильный\n",
            "Target: Cincinnati (Ohio) 513231 **** Mobile\n",
            "Prediction: cincinnati ( ohio ) 513231 * * * * mobile\n",
            "\n",
            "Top 5\n",
            "BLEU score 1.0\n",
            "Source: 12844\n",
            "Target: 12844\n",
            "Prediction: 12844\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5aa93d6",
      "metadata": {
        "id": "b5aa93d6"
      },
      "source": [
        "\n",
        "## Задание 2 (2 балла).\n",
        "Прочитайте главу про машинный перевод у Журафски и Маннига - https://web.stanford.edu/~jurafsky/slp3/13.pdf\n",
        "Ответьте своими словами в чем заключается техника back translation? Для чего она применяется и что позволяет получить? Опишите по шагам как ее применить к паре en->ru на данных из семинара. Сколько моделей понадобится? Сколько запусков обучения нужно будет сделать?\n",
        "\n",
        "Ответ должен содержать как минимум 10 предложений."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backtranslation - это искусственный способ получить параллельные данные, если параллельных данных мало, но есть много монолингвальных. Применяется для малоресурсных языков: параллельных корпусов с английским для них часто мало, зато есть много моноязычных данных на английском. Позволяет получить синтетические данные, которые получились переводом большого моноязычного корпуса моделью, обученной на маленьком параллельном. Таким образом, размер параллельного корпуса \"искусственно\" увеличивается.\n",
        "\n",
        "В нашем случае - если есть маленький англо-русский параллельный корпус и много моноязычных данных на русском.\n",
        "\n",
        "Шаг 1: обучаем модель для перевода с русского на английский на маленьком параллельном корпусе.\n",
        "\n",
        "Шаг 2: запускаем обученную в Шаге 1 модель на монолингвальном русскоязычном корпусе и получаем переводы на английский.\n",
        "\n",
        "Шаг 3: доливаем русские тексты и их переводы на английский, полученные в Шаге 2, в маленький параллельный корпус, и получаем большой корпус.\n",
        "\n",
        "Шаг 4: обучаем (другую, не ту, что в Шаге 1) модель на перевод в желаемом направлении, т.е. с английского на русский, на корпусе, полученном в Шаге 3.\n",
        "\n",
        "Всего 2 модели и 2 запуска обучения (по 1 на каждую, Шаг 1 и 4) и 1 запуск инференса (Шаг 2)."
      ],
      "metadata": {
        "id": "zgTzktWwKHLS"
      },
      "id": "zgTzktWwKHLS"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f5255baf9d104a76afe17984b6d8c4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_736ddcfd1e6b4d11a6d65da94f297429",
              "IPY_MODEL_4124186c0e4149438a3dd3dd68107216",
              "IPY_MODEL_9de586eb3a53443fb1c307df0f22b123"
            ],
            "layout": "IPY_MODEL_05a7a19793424188988a1c72fcbe1780"
          }
        },
        "736ddcfd1e6b4d11a6d65da94f297429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e0c96b1f10848dc8fdbd7bbe4bb5d65",
            "placeholder": "​",
            "style": "IPY_MODEL_1c6de2eaa9224d778dd6ffec1aa48a27",
            "value": "100%"
          }
        },
        "4124186c0e4149438a3dd3dd68107216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d4a46df8c14431caad564e8b3ccae86",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72d913ff4c1c43bba35140bc3bf596c6",
            "value": 20
          }
        },
        "9de586eb3a53443fb1c307df0f22b123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2919899300944e1591014916c85eb277",
            "placeholder": "​",
            "style": "IPY_MODEL_a3d37595d7d54e9cbf68dea394b879cc",
            "value": " 20/20 [00:11&lt;00:00,  1.79it/s]"
          }
        },
        "05a7a19793424188988a1c72fcbe1780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e0c96b1f10848dc8fdbd7bbe4bb5d65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c6de2eaa9224d778dd6ffec1aa48a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d4a46df8c14431caad564e8b3ccae86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72d913ff4c1c43bba35140bc3bf596c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2919899300944e1591014916c85eb277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3d37595d7d54e9cbf68dea394b879cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}